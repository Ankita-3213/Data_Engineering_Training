{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark==3.5.1 delta-spark==3.1.0"
      ],
      "metadata": {
        "id": "mlUuxw23zoxY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "y07CaqJqyyjC",
        "outputId": "33206bec-0dd0-4c45-d3e0-5711c7538cd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79c409437a90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3eef9ffd1a22:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>DeltaLakeColab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Delta supported spark session\n",
        "from delta import configure_spark_with_delta_pip\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "builder = SparkSession.builder \\\n",
        "    .appName(\"DeltaLakeColab\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Data\n",
        "csv_data =\"\"\"\n",
        "transaction_id,customer_name,region,product,category,quantity,unit_price,date\n",
        "1,Rajesh,North,Laptop,Electronics,1,55000,2024-01-12\n",
        "2,Sneha,West,Refrigerator,Electronics,1,32000,2024-02-05\n",
        "3,Anil,South,Shampoo,Personal Care,5,150,2024-01-17\n",
        "4,Divya,North,Mobile,Electronics,2,20000,2024-03-22\n",
        "5,Vikram,East,Washing Machine,Electronics,1,28000,2024-02-28\n",
        "6,Preeti,West,Sneakers,Fashion,2,4000,2024-01-31\n",
        "7,Aman,South,TV,Electronics,1,45000,2024-02-15\n",
        "8,Isha,North,Notebook,Stationery,10,60,2024-01-10\n",
        "9,Kunal,East,Pencil,Stationery,20,10,2024-03-05\n",
        "10,Tanvi,West,Face Cream,Personal Care,3,200,2024-03-19\n",
        "\"\"\"\n",
        "with open(\"sales_transactions.csv\", \"w\") as f:\n",
        "  f.write(csv_data)"
      ],
      "metadata": {
        "id": "BYZUtUvwzgSI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Ingest & Save"
      ],
      "metadata": {
        "id": "URIXLb7l0AtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading csv in PySpark DataFrame\n",
        "\n",
        "df_spark = spark.read.csv('sales_transactions.csv', header=True, inferSchema=True)\n",
        "df_spark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uzSUoDqz1Lk",
        "outputId": "79bb5351-ece9-4fc5-e2d2-a77bc7f1e60b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+\n",
            "|transaction_id|customer_name|region|        product|     category|quantity|unit_price|      date|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+\n",
            "|             1|       Rajesh| North|         Laptop|  Electronics|       1|     55000|2024-01-12|\n",
            "|             2|        Sneha|  West|   Refrigerator|  Electronics|       1|     32000|2024-02-05|\n",
            "|             3|         Anil| South|        Shampoo|Personal Care|       5|       150|2024-01-17|\n",
            "|             4|        Divya| North|         Mobile|  Electronics|       2|     20000|2024-03-22|\n",
            "|             5|       Vikram|  East|Washing Machine|  Electronics|       1|     28000|2024-02-28|\n",
            "|             6|       Preeti|  West|       Sneakers|      Fashion|       2|      4000|2024-01-31|\n",
            "|             7|         Aman| South|             TV|  Electronics|       1|     45000|2024-02-15|\n",
            "|             8|         Isha| North|       Notebook|   Stationery|      10|        60|2024-01-10|\n",
            "|             9|        Kunal|  East|         Pencil|   Stationery|      20|        10|2024-03-05|\n",
            "|            10|        Tanvi|  West|     Face Cream|Personal Care|       3|       200|2024-03-19|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save it in Parquet & Delta formats\n",
        "df_spark.write.format(\"delta\").mode(\"overwrite\").save(\"sales_transactions\")\n",
        "df_delta = spark.read.format(\"delta\").load(\"sales_transactions\")\n",
        "df_delta.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xkM2dR_0if9",
        "outputId": "eaad2492-f643-4350-98c3-05ccb3d78193"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+\n",
            "|transaction_id|customer_name|region|        product|     category|quantity|unit_price|      date|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+\n",
            "|             1|       Rajesh| North|         Laptop|  Electronics|       1|     55000|2024-01-12|\n",
            "|             2|        Sneha|  West|   Refrigerator|  Electronics|       1|     32000|2024-02-05|\n",
            "|             3|         Anil| South|        Shampoo|Personal Care|       5|       150|2024-01-17|\n",
            "|             4|        Divya| North|         Mobile|  Electronics|       2|     20000|2024-03-22|\n",
            "|             5|       Vikram|  East|Washing Machine|  Electronics|       1|     28000|2024-02-28|\n",
            "|             6|       Preeti|  West|       Sneakers|      Fashion|       2|      4000|2024-01-31|\n",
            "|             7|         Aman| South|             TV|  Electronics|       1|     45000|2024-02-15|\n",
            "|             8|         Isha| North|       Notebook|   Stationery|      10|        60|2024-01-10|\n",
            "|             9|        Kunal|  East|         Pencil|   Stationery|      20|        10|2024-03-05|\n",
            "|            10|        Tanvi|  West|     Face Cream|Personal Care|       3|       200|2024-03-19|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving as parquet\n",
        "df_spark.write.mode(\"overwrite\").parquet(\"sales_parquet\")\n"
      ],
      "metadata": {
        "id": "6PRDwvih3HPM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Data Transformations"
      ],
      "metadata": {
        "id": "pHKRRR1X3uTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column total_amount = quantity * unit_price\n",
        "from pyspark.sql.functions import col\n",
        "from delta.tables import DeltaTable\n",
        "\n",
        "df_delta = spark.read.format(\"delta\").load(\"sales_transactions\")\n",
        "\n",
        "df_total = df_delta.withColumn(\"total_amount\", col(\"quantity\") * col(\"unit_price\"))\n",
        "df_total.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(\"sales_transactions\")\n",
        "\n",
        "DeltaTable.forPath(spark, \"sales_transactions\").toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW5vGZt53ld2",
        "outputId": "fb6acd2e-136d-4e54-cf12-bc9d2d34260e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+------------+\n",
            "|transaction_id|customer_name|region|        product|     category|quantity|unit_price|      date|total_amount|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+------------+\n",
            "|             1|       Rajesh| North|         Laptop|  Electronics|       1|     55000|2024-01-12|       55000|\n",
            "|             2|        Sneha|  West|   Refrigerator|  Electronics|       1|     32000|2024-02-05|       32000|\n",
            "|             3|         Anil| South|        Shampoo|Personal Care|       5|       150|2024-01-17|         750|\n",
            "|             4|        Divya| North|         Mobile|  Electronics|       2|     20000|2024-03-22|       40000|\n",
            "|             5|       Vikram|  East|Washing Machine|  Electronics|       1|     28000|2024-02-28|       28000|\n",
            "|             6|       Preeti|  West|       Sneakers|      Fashion|       2|      4000|2024-01-31|        8000|\n",
            "|             7|         Aman| South|             TV|  Electronics|       1|     45000|2024-02-15|       45000|\n",
            "|             8|         Isha| North|       Notebook|   Stationery|      10|        60|2024-01-10|         600|\n",
            "|             9|        Kunal|  East|         Pencil|   Stationery|      20|        10|2024-03-05|         200|\n",
            "|            10|        Tanvi|  West|     Face Cream|Personal Care|       3|       200|2024-03-19|         600|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add another column month extracted from the date\n",
        "from pyspark.sql.functions import month\n",
        "\n",
        "df_month = df_delta.withColumn(\"month\", month(col(\"date\")))\n",
        "df_month.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(\"sales_transactions\")\n",
        "\n",
        "DeltaTable.forPath(spark, \"sales_transactions\").toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkhql6hf_hsG",
        "outputId": "93e8e998-50fb-4ff7-c973-f4eb08a76c18"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+-----+\n",
            "|transaction_id|customer_name|region|        product|     category|quantity|unit_price|      date|month|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+-----+\n",
            "|             1|       Rajesh| North|         Laptop|  Electronics|       1|     55000|2024-01-12|    1|\n",
            "|             2|        Sneha|  West|   Refrigerator|  Electronics|       1|     32000|2024-02-05|    2|\n",
            "|             3|         Anil| South|        Shampoo|Personal Care|       5|       150|2024-01-17|    1|\n",
            "|             4|        Divya| North|         Mobile|  Electronics|       2|     20000|2024-03-22|    3|\n",
            "|             5|       Vikram|  East|Washing Machine|  Electronics|       1|     28000|2024-02-28|    2|\n",
            "|             6|       Preeti|  West|       Sneakers|      Fashion|       2|      4000|2024-01-31|    1|\n",
            "|             7|         Aman| South|             TV|  Electronics|       1|     45000|2024-02-15|    2|\n",
            "|             8|         Isha| North|       Notebook|   Stationery|      10|        60|2024-01-10|    1|\n",
            "|             9|        Kunal|  East|         Pencil|   Stationery|      20|        10|2024-03-05|    3|\n",
            "|            10|        Tanvi|  West|     Face Cream|Personal Care|       3|       200|2024-03-19|    3|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format date as dd-MMM-yyyy and display\n",
        "from pyspark.sql.functions import date_format\n",
        "\n",
        "df_date = df_delta.withColumn(\"formatted_date\", date_format(\"date\", \"dd-MMM-yyyy\"))\n",
        "df_date.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(\"sales_transactions\")\n",
        "\n",
        "# Selecting specific columns from sales_transactions\n",
        "DeltaTable.forPath(spark, \"sales_transactions\").toDF().select(\"transaction_id\", \"date\", \"formatted_date\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VuSPThqI2vP",
        "outputId": "bc932bd2-f00a-4934-a705-0fc76ad3b9a4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----------+--------------+\n",
            "|transaction_id|      date|formatted_date|\n",
            "+--------------+----------+--------------+\n",
            "|             1|2024-01-12|   12-Jan-2024|\n",
            "|             2|2024-02-05|   05-Feb-2024|\n",
            "|             3|2024-01-17|   17-Jan-2024|\n",
            "|             4|2024-03-22|   22-Mar-2024|\n",
            "|             5|2024-02-28|   28-Feb-2024|\n",
            "|             6|2024-01-31|   31-Jan-2024|\n",
            "|             7|2024-02-15|   15-Feb-2024|\n",
            "|             8|2024-01-10|   10-Jan-2024|\n",
            "|             9|2024-03-05|   05-Mar-2024|\n",
            "|            10|2024-03-19|   19-Mar-2024|\n",
            "+--------------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcoye29iNvOU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a column is_high_value (TRUE if total_amount > 30,000 , else FALSE)\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# We have to read/load delta table again for new schema\n",
        "df_updated = spark.read.format(\"delta\").load(\"sales_transactions\")\n",
        "\n",
        "df_total = df_updated.withColumn(\"total_amount\", col(\"quantity\") * col(\"unit_price\"))\n",
        "\n",
        "df_high = df_total.withColumn(\"is_high_value\", when(col(\"total_amount\") > 30000, True).otherwise(False))\n",
        "df_high.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(\"sales_transactions\")\n",
        "\n",
        "DeltaTable.forPath(spark, \"sales_transactions\").toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jOHaNIKrXU",
        "outputId": "f95ca23e-5fa0-40c8-c08c-f6112544a884"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "|transaction_id|customer_name|region|        product|     category|quantity|unit_price|      date|formatted_date|total_amount|is_high_value|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "|             1|       Rajesh| North|         Laptop|  Electronics|       1|     55000|2024-01-12|   12-Jan-2024|       55000|         true|\n",
            "|             2|        Sneha|  West|   Refrigerator|  Electronics|       1|     32000|2024-02-05|   05-Feb-2024|       32000|         true|\n",
            "|             3|         Anil| South|        Shampoo|Personal Care|       5|       150|2024-01-17|   17-Jan-2024|         750|        false|\n",
            "|             4|        Divya| North|         Mobile|  Electronics|       2|     20000|2024-03-22|   22-Mar-2024|       40000|         true|\n",
            "|             5|       Vikram|  East|Washing Machine|  Electronics|       1|     28000|2024-02-28|   28-Feb-2024|       28000|        false|\n",
            "|             6|       Preeti|  West|       Sneakers|      Fashion|       2|      4000|2024-01-31|   31-Jan-2024|        8000|        false|\n",
            "|             7|         Aman| South|             TV|  Electronics|       1|     45000|2024-02-15|   15-Feb-2024|       45000|         true|\n",
            "|             8|         Isha| North|       Notebook|   Stationery|      10|        60|2024-01-10|   10-Jan-2024|         600|        false|\n",
            "|             9|        Kunal|  East|         Pencil|   Stationery|      20|        10|2024-03-05|   05-Mar-2024|         200|        false|\n",
            "|            10|        Tanvi|  West|     Face Cream|Personal Care|       3|       200|2024-03-19|   19-Mar-2024|         600|        false|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 3: Aggregations & Insights"
      ],
      "metadata": {
        "id": "lM1MJ7EVPEPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a view\n",
        "df =spark.read.format(\"delta\").load(\"sales_transactions\")\n",
        "df.createOrReplaceTempView(\"sales_transactions\")"
      ],
      "metadata": {
        "id": "C6Ft88y4QgqY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count transactions per region\n",
        "spark.sql(\"select region, count(*) as TransactionCount from sales_transactions group by region\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL2IF1g5PD3o",
        "outputId": "f46a54a5-9e21-47ee-efd5-9304d362ef1b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------+\n",
            "|region|TransactionCount|\n",
            "+------+----------------+\n",
            "| South|               2|\n",
            "|  East|               2|\n",
            "|  West|               3|\n",
            "| North|               3|\n",
            "+------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 3 categories by total sales amount\n",
        "spark.sql(\"SELECT category, SUM(total_amount) AS total_sales FROM sales_transactions GROUP BY category ORDER BY total_sales DESC LIMIT 3\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46d_jynjMiX6",
        "outputId": "60be2cf2-8efa-4f1e-d39b-0c4575eba8af"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------+\n",
            "|     category|total_sales|\n",
            "+-------------+-----------+\n",
            "|  Electronics|     200000|\n",
            "|      Fashion|       8000|\n",
            "|Personal Care|       1350|\n",
            "+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find month-wise revenue trend\n",
        "spark.sql(\"\"\"\n",
        "    SELECT MONTH(date) AS month, SUM(total_amount) AS revenue\n",
        "    FROM sales_transactions\n",
        "    GROUP BY month\n",
        "    ORDER BY month\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvtVgBZ-WkwW",
        "outputId": "f899b4a2-d2e6-4dd9-80d2-d334d09c6dcb"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+\n",
            "|month|revenue|\n",
            "+-----+-------+\n",
            "|    1|  64350|\n",
            "|    2| 105000|\n",
            "|    3|  40800|\n",
            "+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show customer(s) who made the highest purchase in one transaction\n",
        "spark.sql(\"\"\"\n",
        "    SELECT customer_name, total_amount\n",
        "    FROM sales_transactions\n",
        "    WHERE total_amount = (SELECT MAX(total_amount) FROM sales_transactions)\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvPegytGWeNs",
        "outputId": "c8de9d66-9848-4c0f-fdbc-a36d8703d7e0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+------------+\n",
            "|customer_name|total_amount|\n",
            "+-------------+------------+\n",
            "|       Rajesh|       55000|\n",
            "+-------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total sales done in Q1 (Jan–Mar)\n",
        "spark.sql(\"select sum(total_amount)as sale_q1 from sales_transactions where month(date) between 1 and 3\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8PXB8O6WrMy",
        "outputId": "454c0931-fd2a-4c6a-d6e2-d7048c756fc9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|sale_q1|\n",
            "+-------+\n",
            "| 210150|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4: Update and Delete Scenarios\n"
      ],
      "metadata": {
        "id": "m2ECrxWzgWSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update price of all Stationery items to increase by 10%\n",
        "\n",
        "delta_table = DeltaTable.forPath(spark, \"sales_transactions\")\n",
        "delta_table.update(\n",
        "    condition=\"category = 'stationery'\",\n",
        "    set= {\"unit_price\": \"unit_price * 1.1\"})\n",
        "\n",
        "delta_table.toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOP6e5gEfemW",
        "outputId": "aab7374f-c9b0-4dcf-df45-a15598d65246"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "|transaction_id|customer_name|region|        product|     category|quantity|unit_price|      date|formatted_date|total_amount|is_high_value|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "|             1|       Rajesh| North|         Laptop|  Electronics|       1|     55000|2024-01-12|   12-Jan-2024|       55000|         true|\n",
            "|             2|        Sneha|  West|   Refrigerator|  Electronics|       1|     32000|2024-02-05|   05-Feb-2024|       32000|         true|\n",
            "|             3|         Anil| South|        Shampoo|Personal Care|       5|       150|2024-01-17|   17-Jan-2024|         750|        false|\n",
            "|             4|        Divya| North|         Mobile|  Electronics|       2|     20000|2024-03-22|   22-Mar-2024|       40000|         true|\n",
            "|             5|       Vikram|  East|Washing Machine|  Electronics|       1|     28000|2024-02-28|   28-Feb-2024|       28000|        false|\n",
            "|             6|       Preeti|  West|       Sneakers|      Fashion|       2|      4000|2024-01-31|   31-Jan-2024|        8000|        false|\n",
            "|             7|         Aman| South|             TV|  Electronics|       1|     45000|2024-02-15|   15-Feb-2024|       45000|         true|\n",
            "|             8|         Isha| North|       Notebook|   Stationery|      10|        60|2024-01-10|   10-Jan-2024|         600|        false|\n",
            "|             9|        Kunal|  East|         Pencil|   Stationery|      20|        10|2024-03-05|   05-Mar-2024|         200|        false|\n",
            "|            10|        Tanvi|  West|     Face Cream|Personal Care|       3|       200|2024-03-19|   19-Mar-2024|         600|        false|\n",
            "+--------------+-------------+------+---------------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete all records with quantity < 3\n",
        "\n",
        "delta_table.delete(condition=\"quantity < 3\")\n",
        "delta_table.toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSbvINt4ggji",
        "outputId": "054b195e-24d4-4ee6-fa37-e61539c53391"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+------+----------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "|transaction_id|customer_name|region|   product|     category|quantity|unit_price|      date|formatted_date|total_amount|is_high_value|\n",
            "+--------------+-------------+------+----------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "|             3|         Anil| South|   Shampoo|Personal Care|       5|       150|2024-01-17|   17-Jan-2024|         750|        false|\n",
            "|             8|         Isha| North|  Notebook|   Stationery|      10|        60|2024-01-10|   10-Jan-2024|         600|        false|\n",
            "|             9|        Kunal|  East|    Pencil|   Stationery|      20|        10|2024-03-05|   05-Mar-2024|         200|        false|\n",
            "|            10|        Tanvi|  West|Face Cream|Personal Care|       3|       200|2024-03-19|   19-Mar-2024|         600|        false|\n",
            "+--------------+-------------+------+----------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new row into the Delta Table with today's transaction data\n",
        "from datetime import date\n",
        "from pyspark.sql import Row\n",
        "\n",
        "delta_table = DeltaTable.forPath(spark, \"sales_transactions\")\n",
        "\n",
        "new = [Row(\n",
        "    transaction_id=11,\n",
        "    customer_name=\"Ananya\",\n",
        "    region=\"North\",\n",
        "    product=\"Headphones\",\n",
        "    category=\"Electronics\",\n",
        "    quantity=2,\n",
        "    unit_price=3000,\n",
        "    date=date.today(),\n",
        "    formatted_date=date.today().strftime(\"%d-%b-%Y\"),\n",
        "    total_amount=2 * 3000,\n",
        "    is_high_value=True\n",
        ")]\n",
        "\n",
        "df_insert = spark.createDataFrame(new, [\"transaction_id\", \"customer_name\", \"region\", \"product\", \"category\", \"quantity\", \"unit_price\", \"formatted_date\",\"date\", \"total_amount\", \"is_high_value\" ])\n",
        "\n",
        "delta_table.alias(\"target\").merge(\n",
        "    df_insert.alias(\"source\"),\n",
        "    \"target.transaction_id = source.transaction_id\"\n",
        ").whenNotMatchedInsert(values={\n",
        "    \"transaction_id\": \"source.transaction_id\",\n",
        "    \"customer_name\": \"source.customer_name\",\n",
        "    \"region\": \"source.region\",\n",
        "    \"product\": \"source.product\",\n",
        "    \"category\": \"source.category\",\n",
        "    \"quantity\": \"source.quantity\",\n",
        "    \"unit_price\": \"source.unit_price\",\n",
        "    \"date\": \"source.date\",\n",
        "    \"formatted_date\": \"source.formatted_date\",\n",
        "    \"total_amount\": \"source.total_amount\",\n",
        "    \"is_high_value\": \"source.is_high_value\"}).execute()\n",
        "\n",
        "delta_table.toDF().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw7XBSMkgmUy",
        "outputId": "9a2b2403-cd2e-4040-fdcb-89590c7dc77f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+------+----------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "|transaction_id|customer_name|region|   product|     category|quantity|unit_price|      date|formatted_date|total_amount|is_high_value|\n",
            "+--------------+-------------+------+----------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "|             3|         Anil| South|   Shampoo|Personal Care|       5|       150|2024-01-17|   17-Jan-2024|         750|        false|\n",
            "|             8|         Isha| North|  Notebook|   Stationery|      10|        60|2024-01-10|   10-Jan-2024|         600|        false|\n",
            "|             9|        Kunal|  East|    Pencil|   Stationery|      20|        10|2024-03-05|   05-Mar-2024|         200|        false|\n",
            "|            10|        Tanvi|  West|Face Cream|Personal Care|       3|       200|2024-03-19|   19-Mar-2024|         600|        false|\n",
            "|            11|       Ananya| North|Headphones|  Electronics|       2|      3000|2025-08-08|   08-Aug-2025|        6000|        false|\n",
            "+--------------+-------------+------+----------+-------------+--------+----------+----------+--------------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5: Partitioning & Optimization"
      ],
      "metadata": {
        "id": "r_AWKEVthdeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-write the Delta table partitioned by region\n",
        "\n",
        "df = spark.read.format(\"delta\").load(\"sales_transactions\")\n",
        "\n",
        "partitioned_path = \"sales_transactions_by_region\"\n",
        "\n",
        "df.write.format(\"delta\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .partitionBy(\"region\") \\\n",
        "    .save(partitioned_path)\n"
      ],
      "metadata": {
        "id": "32t4CTfUhm6U"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a second Delta table partitioned by month\n",
        "\n",
        "from pyspark.sql.functions import month\n",
        "\n",
        "df = spark.read.format(\"delta\").load(\"sales_transactions\")\n",
        "\n",
        "df_with_month = df.withColumn(\"month\", month(df[\"date\"]))\n",
        "\n",
        "month_partitioned_path = \"sales_transactions_by_month\"\n",
        "\n",
        "df_with_month.write.format(\"delta\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .partitionBy(\"month\") \\\n",
        "    .save(month_partitioned_path)\n"
      ],
      "metadata": {
        "id": "9FZUR9-khqcT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJToYnKDqYVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}