{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9C3-l305qBf9"
      },
      "outputs": [],
      "source": [
        "!pip install delta-spark==3.2.0 -q\n",
        "import pyspark\n",
        "from delta import *\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SparkSession with Delta Lake extensions\n",
        "# The '.config(...)' lines are crucial for enabling Delta Lake's features\n",
        "builder = pyspark.sql.SparkSession.builder.appName(\"DeltaTutorial\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "\n",
        "# Get or create the SparkSession\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "\n",
        "print(\"Spark and Delta Lake are ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYt-M4ckqC3s",
        "outputId": "5283118d-da89-4bde-a9d5-351e553ed2f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark and Delta Lake are ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstration of Managed and Unmanaged Tables\n",
        "# Create a dataframe\n",
        "\n",
        "data=[(\"Amit\",28), (\"Priya\", 24), (\"Rohan\", 25)]\n",
        "df = spark.createDataFrame(data, ['name', 'age'])\n",
        "\n",
        "# Creating table\n",
        "df.write.format(\"delta\").saveAsTable(\"managed_people\")\n",
        "\n",
        "# Show table\n",
        "spark.sql(\"Select * from managed_people\").show()\n",
        "\n",
        "# Checking its Location\n",
        "location = spark.sql(\"DESCRIBE DETAIL managed_people\").collect()[0]['location']\n",
        "print(\"Managed Table Location: \", location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcxHdAqJqIJZ",
        "outputId": "4e62bdd3-7d9c-476e-98f2-9af90266a375"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|Priya| 24|\n",
            "|Rohan| 25|\n",
            "| Amit| 28|\n",
            "+-----+---+\n",
            "\n",
            "Managed Table Location:  file:/content/spark-warehouse/managed_people\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"DROP TABLE managed_people\")"
      ],
      "metadata": {
        "id": "WlRHFUFnstkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Managed Tables\n",
        "\n",
        "The above was example of managed table -\n",
        "Where in when we delete the table , the corresponding dataframe also gets deleted and data gets deleted permanently.\n",
        "\n",
        "This happens as df and table are in same cell. So accidently if we delete table all the data along with metadata gets deleted.\n"
      ],
      "metadata": {
        "id": "td0pIjjzreCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unmanaged Tables\n",
        "\n",
        "When we read data from other formats like csv file or from dbfs in databricks case , even if we delete table the data still remains in form of files.\n",
        "\n",
        "This happens as we only delete the df / table we use and not from original source.\n",
        "\n",
        "These are called Unmanaged Tables"
      ],
      "metadata": {
        "id": "VuQAtMEbsHiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unmanaged Tables\n",
        "data=[(\"Amit\",28), (\"Priya\", 24), (\"Rohan\", 25)]\n",
        "\n",
        "with open ('unmanaged.csv','w')as f:\n",
        "  f.write(\"name,age\\n\")\n",
        "  for name, age in data:\n",
        "    f.write(f\"{name},{age}\\n\")"
      ],
      "metadata": {
        "id": "ibmEBZTZqOCa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_unmanaged = spark.read.csv('/content/unmanaged.csv',header=True ,inferSchema=True)\n",
        "df_unmanaged.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvB_fx4jtUd0",
        "outputId": "8f2411e1-f53c-428e-8b58-a2c4c3f8201a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "| Amit| 28|\n",
            "|Priya| 24|\n",
            "|Rohan| 25|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_unmanaged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "c986XlcYuN9S",
        "outputId": "4bc9ca7b-200d-4619-ee77-92834a0e0996"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Table\n",
        "df.write.format(\"delta\").saveAsTable(\"unmanaged_people\")"
      ],
      "metadata": {
        "id": "4Q1OfwUVxiBX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show table\n",
        "spark.sql(\"Select * from unmanaged_people\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HrGxPmq05OJ",
        "outputId": "89f7bc9f-95f9-4afb-eca5-abbefd591c5e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|Priya| 24|\n",
            "|Rohan| 25|\n",
            "| Amit| 28|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting the table\n",
        "spark.sql(\"drop table unmanaged_people\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDwcQYU71A4Q",
        "outputId": "d5b3f198-c051-404f-b51e-6c968668c3c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Additional and optional\n",
        "# Saving as view\n",
        "\n",
        "df_unmanaged.createOrReplaceTempView('unmanaged_view')\n",
        "spark.sql(\"Select * from unmanaged_view\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-yTcMJuwnDL",
        "outputId": "9394d92f-4bda-49ef-b62c-ce792cb5605b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "| Amit| 28|\n",
            "|Priya| 24|\n",
            "|Rohan| 25|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting view\n",
        "spark.sql(\"drop view unmanaged_view\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVlvpynVxV7c",
        "outputId": "058a8d7a-2521-4874-d97a-f3f914dfcba9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}