{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nBb1Tc-s5sZv"
      },
      "outputs": [],
      "source": [
        "!pip install delta-spark==3.2.0 -q\n",
        "import pyspark\n",
        "from delta import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Create a SparkSession with Delta Lake extensions\n",
        "# The '.config(...)' lines are crucial for enabling Delta Lake's features\n",
        "builder = pyspark.sql.SparkSession.builder.appName(\"DeltaTutorial\") \\\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "\n",
        "# Get or create the SparkSession\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "customer = spark.read.csv('Customers.csv', header=True, inferSchema=True)\n",
        "customer.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycR_wrsB6ibz",
        "outputId": "01ebf684-d2c3-45a4-e046-44dca38952d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+--------------------+------+\n",
            "|customer_id|             name|               email|region|\n",
            "+-----------+-----------------+--------------------+------+\n",
            "|          1|    Claire Dunphy|  claire@example.com|  East|\n",
            "|          2|      Phil Dunphy|realtorphil@examp...|  East|\n",
            "|          3|    Jay Prichette|     jay@example.com| North|\n",
            "|          4| Gloria Prichette|  gloria@example.com| North|\n",
            "|          5|Mitchel Prichette|lawyermitch@examp...| South|\n",
            "|          6|   Cameron Tucker|     cam@example.com| South|\n",
            "|          7|     Haley Dunphy|   haley@example.com|  West|\n",
            "|          8|   Dylan Marshall|   dylan@example.com|  West|\n",
            "+-----------+-----------------+--------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order = spark.read.csv('orders.csv', header=True, inferSchema=True)\n",
        "order.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DADd8loFCUbs",
        "outputId": "96352e54-5ce6-4d56-87ff-23c28cad3f93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+----------+------------+\n",
            "|order_id|customer_id|order_date|total_amount|\n",
            "+--------+-----------+----------+------------+\n",
            "|       1|          1|01-08-2025|        2500|\n",
            "|       2|          2|05-08-2025|        1800|\n",
            "|       3|          3|02-08-2025|        3200|\n",
            "|       4|          4|10-08-2025|        1450|\n",
            "|       5|          5|15-08-2025|        2200|\n",
            "|       6|          6|07-08-2025|        2750|\n",
            "|       7|          7|18-08-2025|         900|\n",
            "|       8|          8|12-08-2025|        1100|\n",
            "+--------+-----------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delivery = spark.read.csv('delivery_status.csv', header=True, inferSchema=True)\n",
        "delivery.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beaQMMYiCgKk",
        "outputId": "09e248a2-5d0f-4661-da3b-590d75e77765"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+---------------+----------+\n",
            "|delivery_id|order_id|delivery_status|updated_on|\n",
            "+-----------+--------+---------------+----------+\n",
            "|          1|       1|      DELIVERED|05-08-2025|\n",
            "|          2|       2|     IN_TRANSIT|06-08-2025|\n",
            "|          3|       3|      DELIVERED|03-08-2025|\n",
            "|          4|       4|     IN_TRANSIT|11-08-2025|\n",
            "|          5|       5|         PLACED|15-08-2025|\n",
            "|          6|       6|      DELIVERED|08-08-2025|\n",
            "|          7|       7|         PLACED|18-08-2025|\n",
            "|          8|       8|     IN_TRANSIT|13-08-2025|\n",
            "+-----------+--------+---------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "window_spec = Window.partitionBy(\"order_id\").orderBy(desc(\"updated_on\"))\n",
        "\n",
        "latest_delivery = (delivery\n",
        "    .withColumn(\"rn\", row_number().over(window_spec))\n",
        "    .filter(col(\"rn\") == 1)\n",
        "    .drop(\"rn\"))\n",
        "latest_delivery.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndj0o7UTCszp",
        "outputId": "b1db7271-e22f-43b0-e707-d86afedacfe6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+---------------+----------+\n",
            "|delivery_id|order_id|delivery_status|updated_on|\n",
            "+-----------+--------+---------------+----------+\n",
            "|          1|       1|      DELIVERED|05-08-2025|\n",
            "|          2|       2|     IN_TRANSIT|06-08-2025|\n",
            "|          3|       3|      DELIVERED|03-08-2025|\n",
            "|          4|       4|     IN_TRANSIT|11-08-2025|\n",
            "|          5|       5|         PLACED|15-08-2025|\n",
            "|          6|       6|      DELIVERED|08-08-2025|\n",
            "|          7|       7|         PLACED|18-08-2025|\n",
            "|          8|       8|     IN_TRANSIT|13-08-2025|\n",
            "+-----------+--------+---------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order_latest = order.join(latest_delivery, \"order_id\", \"left\")\n",
        "order_latest.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP4phRVZDT5-",
        "outputId": "5843ff39-0c36-4b4b-eda2-9a16e0e9fb13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+----------+------------+-----------+---------------+----------+\n",
            "|order_id|customer_id|order_date|total_amount|delivery_id|delivery_status|updated_on|\n",
            "+--------+-----------+----------+------------+-----------+---------------+----------+\n",
            "|       1|          1|01-08-2025|        2500|          1|      DELIVERED|05-08-2025|\n",
            "|       2|          2|05-08-2025|        1800|          2|     IN_TRANSIT|06-08-2025|\n",
            "|       3|          3|02-08-2025|        3200|          3|      DELIVERED|03-08-2025|\n",
            "|       4|          4|10-08-2025|        1450|          4|     IN_TRANSIT|11-08-2025|\n",
            "|       5|          5|15-08-2025|        2200|          5|         PLACED|15-08-2025|\n",
            "|       6|          6|07-08-2025|        2750|          6|      DELIVERED|08-08-2025|\n",
            "|       7|          7|18-08-2025|         900|          7|         PLACED|18-08-2025|\n",
            "|       8|          8|12-08-2025|        1100|          8|     IN_TRANSIT|13-08-2025|\n",
            "+--------+-----------+----------+------------+-----------+---------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving to delta\n",
        "order_latest.write.format(\"delta\").mode(\"overwrite\").save(\"/tmp/orders_with_latest_status_delta\")"
      ],
      "metadata": {
        "id": "MKkM8yyLDd6W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order_latest.write.mode('overwrite').csv('order_latest_csv', header=True)"
      ],
      "metadata": {
        "id": "K5fjRJZHGZq_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(order_latest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "foltriIqDxz-",
        "outputId": "ba3cabac-219a-4df7-891c-fc9eda82a677"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order_latest.createOrReplaceTempView('order_latest')"
      ],
      "metadata": {
        "id": "p3frBU7JD84b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer.createOrReplaceTempView('customer')"
      ],
      "metadata": {
        "id": "IYIDVTe4Ft4q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_delayed_customers = spark.sql(\"\"\"\n",
        "    SELECT c.name AS customer_name,\n",
        "           COUNT(*) AS delayed_orders\n",
        "    FROM order_latest o\n",
        "    JOIN customer c ON o.customer_id = c.customer_id\n",
        "    WHERE o.delivery_status != 'DELIVERED'\n",
        "    GROUP BY c.name\n",
        "    ORDER BY delayed_orders DESC\n",
        "    LIMIT 5\n",
        "\"\"\")\n",
        "\n",
        "top_delayed_customers.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUCLpWF3FTTb",
        "outputId": "5014c305-f266-4563-9970-061015846041"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------------+\n",
            "|    customer_name|delayed_orders|\n",
            "+-----------------+--------------+\n",
            "|   Dylan Marshall|             1|\n",
            "|Mitchel Prichette|             1|\n",
            "|      Phil Dunphy|             1|\n",
            "| Gloria Prichette|             1|\n",
            "|     Haley Dunphy|             1|\n",
            "+-----------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pg5X0aR3Fngd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}